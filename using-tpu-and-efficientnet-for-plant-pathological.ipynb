{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"###########################################IMPORTS AND PREPROCESSING ##################################################\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport cv2\nimport seaborn as sns\nimport os\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport pandas.util.testing as tm\nimport PIL  \nfrom PIL import Image  \n\n\n\n\nAUTO = tf.data.experimental.AUTOTUNE\n# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n#*Updating to the final Train_paths_images and Test_paths_images*\n\n\n\npath='../input/plant-pathology-2020-fgvc7/'\ntrain = pd.read_csv(path + '/train.csv')\ntest = pd.read_csv(path + '/test.csv')\nsub = pd.read_csv(path + '/sample_submission.csv')\n\n\ntrain_labels = train.loc[:,'healthy':].values\ntrain_labels_healthy = train.loc[:,'healthy'].values\ntrain_labels_multiple_diseases = train.loc[:,'multiple_diseases'].values\ntrain_labels_rust = train.loc[:,'rust'].values\ntrain_labels_scab = train.loc[:,'scab'].values\n\n\n\n\npath_gc_train = '../input/kaggle-plant-pathology-1/images_gc_train-20200524T112401Z-001/images_gc_train/'\npath_gc_test = '../input/kaggle-plant-pathology-1/images_gc_test-20200524T112222Z-001/images_gc_test/'\n\n\ngcs_path_train = 'gs://plant-pathology-bhavesh/plant-pathology-2020-fgvc7/images_gc_train/'\ngcs_path_test = 'gs://plant-pathology-bhavesh/plant-pathology-2020-fgvc7/images_gc_test/'\n\n\n\nTrain_paths_gc = train.image_id.apply(lambda x: gcs_path_train + str(x) +'.jpg').values\nTest_paths_gc = test.image_id.apply(lambda x: gcs_path_test + str(x) +'.jpg').values\n\ntrain_paths_gc = train.image_id.apply(lambda x: path + '/images/' + str(x) +'.jpg').values\ntest_paths_gc = test.image_id.apply(lambda x: path + '/images/' + str(x) +'.jpg').values\n\npath2 = 'gs://plant-pathology-bhavesh/plant-pathology-2020-fgvc7/images_withborder_train/'\npath3 = 'gs://plant-pathology-bhavesh/plant-pathology-2020-fgvc7/images_withborder_test/'\n\nfilenames = !gsutil ls -r gs://plant-pathology-bhavesh/plant-pathology-2020-fgvc7/images_withborder_train/\n\nint_files = []\nfor id in range(len(filenames)):\n  int_files.append(filenames[id].split('/')[-1].split('.')[0])\n\nfor id,img in enumerate(Train_paths_gc):\n  if img.split('.')[0].split('/')[-1] in int_files:\n    Train_paths_gc[id] = os.path.join(path2,'Train_'+str(id)+'.jpg')\n\n\nfilenames = !gsutil ls -r gs://plant-pathology-bhavesh/plant-pathology-2020-fgvc7/images_withborder_test/\n\nint_files = []\nfor id in range(len(filenames)):\n  int_files.append(filenames[id].split('/')[-1].split('.')[0])\n\nfor id,img in enumerate(Test_paths_gc):\n  if img.split('.')[0].split('/')[-1] in int_files:\n    Test_paths_gc[id] = os.path.join(path2,'Train_'+str(id)+'.jpg')\n\n\n\n#################### 2\n!pip install -U git+https://github.com/qubvel/efficientnet\nimport efficientnet.tfkeras as efn \n\n\nimport pandas as pd\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom tensorflow.keras.models import Sequential , Model\nfrom tensorflow.keras.layers import Dense , Conv2D , Dropout , Flatten , Activation, MaxPooling2D , GlobalAveragePooling2D , Input\nfrom tensorflow.keras.optimizers import Adam , RMSprop \nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau , EarlyStopping , ModelCheckpoint , LearningRateScheduler\n\nimport os\nimport random, re, math\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras import optimizers\nprint(tf.__version__)\nprint(tf.keras.__version__)\n\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.applications import vgg16\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications import MobileNet\n#for reproducible results\n#import random\n#seed_value = 13\n#random.seed(seed_value)\n#np.random.seed(seed_value)\n#tf.random.set_seed(seed_value)\n\n\n#################### 5\nfrom sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()\ntrain_labels_healthy_one_hot = ohe.fit_transform(np.array(train_labels_healthy).reshape(-1,1)).toarray()\ntrain_labels_multiple_diseases = train.loc[:,'multiple_diseases'].values\ntrain_labels_rust = train.loc[:,'rust'].values\ntrain_labels_scab = train.loc[:,'scab'].values\n\nfrom sklearn.preprocessing import OneHotEncoder\nohe = OneHotEncoder()\ntrain_labels_multiple_diseases_one_hot = ohe.fit_transform(np.array(train_labels_multiple_diseases).reshape(-1,1)).toarray()\ntrain_labels_rust_one_hot = ohe.fit_transform(np.array(train_labels_rust).reshape(-1,1)).toarray()\ntrain_labels_scab_one_hot = ohe.fit_transform(np.array(train_labels_scab).reshape(-1,1)).toarray()\n\n\nIMG_SIZE = 256\n\ndef decode_image(filename, label=None, image_size=(IMG_SIZE, IMG_SIZE)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n\n    \n    #convert to numpy and do some cv2 staff mb?\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None, seed=5050):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n           \n    if label is None:\n        return image\n    else:\n        return image, label\n    \ny_train = np.array(train.loc[:,'healthy':])\nfrom sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(Train_paths_gc,y_train,test_size=0.2,shuffle=True)\n    \n\nBATCH_SIZE = 8*strategy.num_replicas_in_sync\ntrain_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train,y_train))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n    )\n\nval_dataset = (tf.data.Dataset\n               .from_tensor_slices((x_val,y_val))\n               .map(decode_image,num_parallel_calls=AUTO)\n               .batch(BATCH_SIZE)\n               .cache()\n               .prefetch(AUTO)\n              )\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(Test_paths_gc)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n    )\nIMG_SIZE = 256\nBATCH_SIZE = 8*strategy.num_replicas_in_sync\nnb_classes = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.astype(float)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##############################Binary Classification followed by FunctionalAPI#############################################\nTrain_images_gc = []\nfor id,img in enumerate(Train_paths_gc):\n  image = cv2.imread(img)\n    #image = cv2.rotate(image, cv2.ROTATE_180)\n  Train_images_gc.append(image/255)\n  if id%100==0:\n     print(id)\nprint('0')\n\n\n\n#print('0')\n\n#history = model.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/content/drive/My Drive/Kaggle - Plant Pathology/binaryhealthy_7.h5')\nprint('2')\n\n#############################################################BINARY MODEL#################################################\n\n#model.load_weights('/content/drive/My Drive/Kaggle - Plant Pathology/binaryhealthy_7.h5')\n#history = model.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/content/drive/My Drive/Kaggle - Plant Pathology/binaryhealthy_14.h5')\nprint('3')\n\n#model = efn.EfficientNetB0(weights='imagenet', include_top=False, pooling='avg', input_shape=(256,256, 3))\n#model = Sequential([model])\n#model.add(Dense(2,activation='softmax'))\n#adam = Adam(learning_rate=0.0003)\n#model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n#print('4')\n#model.load_weights('/content/drive/My Drive/Kaggle - Plant Pathology/binaryhealthy_.h5')\n#history = model.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=4,batch_size=64,validation_split=0.1)\n\n\n\n#Latest Weights binary classification\n#model.save_weights('/content/drive/My Drive/Kaggle - Plant Pathology/binaryhealthy_25.h5')\n#print('5')\n\n\n\n####################################################################Multiclass Model###############################################\n\n\nX1 = efn.EfficientNetB0(weights='imagenet',include_top = False,input_shape=(256,256,3),pooling='avg')\nX0 = Dense(1024,activation='sigmoid')(X1.layers[-1].output)\nX02 = Dense(128,activation='relu')(X0)\nX2 = Dense(2,activation='softmax',name='x2_1')(X02)\nX3 = Dense(2,activation='softmax',name='x2_2')(X02)\nX4 = Dense(2,activation='softmax',name='x2_3')(X02)\n\nmodel = Model(X1.inputs,[X2,X3,X4])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint('1')\n#model.fit(np.array(Train_images_gc),{'x2_1':train_labels_multiple_diseases_one_hot,'x2_2':train_labels_rust_one_hot,'x2_3':train_labels_scab_one_hot},\n#          epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/multiclass_7_extralayers.h5')\n\n#print('2')\n#model.load_weights('/kaggle/working/multiclass_7_extralayers.h5')\n\n#model.fit(np.array(Train_images_gc),{'x2_1':train_labels_multiple_diseases_one_hot,'x2_2':train_labels_rust_one_hot,'x2_3':train_labels_scab_one_hot},\n#          epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/multiclass_14_extralayers.h5')\n\n#print('3')\n#model.load_weights('/kaggle/working/multiclass_14_extralayers.h5')\n\n#model.fit(np.array(Train_images_gc),{'x2_1':train_labels_multiple_diseases_one_hot,'x2_2':train_labels_rust_one_hot,'x2_3':train_labels_scab_one_hot},\n#          epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/multiclass_21_extralayers.h5')\n\n#print('4')\nadam = Adam(learning_rate=0.0003)\n#model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n\n#model.load_weights('/kaggle/working/multiclass_21_extralayers.h5')\n\n#model.fit(np.array(Train_images_gc),{'x2_1':train_labels_multiple_diseases_one_hot,'x2_2':train_labels_rust_one_hot,'x2_3':train_labels_scab_one_hot},\n#          epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/multiclass_28_extralayers.h5')\n\nprint('5')\n#model.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n#model.load_weights('/kaggle/working/multiclass_28_extralayers.h5')\n\n#model.fit(np.array(Train_images_gc),{'x2_1':train_labels_multiple_diseases_one_hot,'x2_2':train_labels_rust_one_hot,'x2_3':train_labels_scab_one_hot},\n#          epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/multiclass_35_extralayers.h5')\n\nprint('6')\n\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\nmodel.load_weights('/kaggle/working/multiclass_35_extralayers.h5')\n\nmodel.fit(np.array(Train_images_gc),{'x2_1':train_labels_multiple_diseases_one_hot,'x2_2':train_labels_rust_one_hot,'x2_3':train_labels_scab_one_hot},\n          epochs=5,batch_size=64,validation_split=0.1)\nmodel.save_weights('/kaggle/working/multiclass_40_extralayers.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_images_gc = []\nfor id,img in enumerate(Train_paths_gc):\n  image = cv2.resize(cv2.imread(img),(450,450),cv2.INTER_AREA)\n    #image = cv2.rotate(image, cv2.ROTATE_180)\n  Train_images_gc.append(image/255)\n  if id%100==0:\n     print(id)\nprint('0')\n\nX1 = efn.EfficientNetB0(weights='imagenet',include_top = False,input_shape=(256,256,3),pooling='avg')\nX0 = Dense(1024,activation='sigmoid')(X1.layers[-1].output)\nX02 = Dense(128,activation='relu')(X0)\nX2 = Dense(2,activation='softmax',name='x2_1')(X02)\nX3 = Dense(2,activation='softmax',name='x2_2')(X02)\nX4 = Dense(2,activation='softmax',name='x2_3')(X02)\n\nmodel = Model(X1.inputs,[X2,X3,X4])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nhistory = model.fit(np.array(Train_images_gc),{'x2_1':train_labels_multiple_diseases_one_hot,'x2_2':train_labels_rust_one_hot,'x2_3':train_labels_scab_one_hot},\n          epochs=40,batch_size=64,validation_split=0.1)\n\n\nplt.plot(history.history['val_x2_1_accuracy'])\nplt.xlabel('cross val acc')\nplt.ylabel('epochs')\nplt.show()\nplt.plot(history.history['val_x2_2_accuracy'])\nplt.xlabel('cross val acc')\nplt.ylabel('epochs')\nplt.show()\nplt.plot(history.history['val_x2_3_accuracy'])\nplt.xlabel('cross val acc')\nplt.ylabel('epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#multiclass_28_extralayers.h5 are the best multiclass weights\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_images_gc = []\nfor id,img in enumerate(Train_paths_gc):\n  image = cv2.imread(img)\n    #image = cv2.rotate(image, cv2.ROTATE_180)\n  Train_images_gc.append(image/255)\n  if id%100==0:\n     print(id)\nprint('0')\n\nmodel = efn.EfficientNetB0(weights='imagenet',include_top = False, input_shape = (256,256,3),pooling = 'avg')\nmodel = Sequential([model])\nmodel.add(Dense(1024,activation = 'sigmoid'))\nmodel.add(Dense(128,activation = 'relu'))\nmodel.add(Dense(2,activation = 'softmax'))\nmodel.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n\n\n\n\nprint('0')\n\n#model.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/binaryhealthy_7.h5')\nprint('2')\n\n#############################################################BINARY MODEL#################################################\n\n#model.load_weights('/kaggle/working/binaryhealthy_7.h5')\n#model.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=7,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/binaryhealthy_14.h5')\n#print('3')\n\n\nprint('4')\n#model.load_weights('/kaggle/working/binaryhealthy_14.h5')\n#model.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=4,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/binaryhealthy_21.h5')\nadam = Adam(learning_rate = 0.0003)\n#print('5')\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n\n\n#model.load_weights('/kaggle/working/binaryhealthy_21.h5')\n#model.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=3,batch_size=64,validation_split=0.1)\n#model.save_weights('/kaggle/working/binaryhealthy_24.h5')\n\n\nmodel.load_weights('/kaggle/working/binaryhealthy_24.h5')\nmodel.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=3,batch_size=64,validation_split=0.1)\nmodel.save_weights('/kaggle/working/binaryhealthy_27.h5')\n\nmodel.load_weights('/kaggle/working/binaryhealthy_27.h5')\nmodel.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=3,batch_size=64,validation_split=0.1)\nmodel.save_weights('/kaggle/working/binaryhealthy_30.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_images_gc = []\nfor id,img in enumerate(Train_paths_gc):\n  image = cv2.imread(img)\n    #image = cv2.rotate(image, cv2.ROTATE_180)\n  Train_images_gc.append(image/255)\n  if id%100==0:\n     print(id)\nprint('0')\n\nmodel = efn.EfficientNetB0(weights='imagenet',include_top = False, input_shape = (256,256,3),pooling = 'avg')\nmodel = Sequential([model])\nmodel.add(Dense(1024,activation = 'sigmoid'))\nmodel.add(Dense(128,activation = 'relu'))\nmodel.add(Dense(2,activation = 'softmax'))\nmodel.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n\nhistory = model.fit(np.array(Train_images_gc),train_labels_healthy_one_hot,epochs=40,batch_size=64,validation_split=0.1)\n\n\nplt.plot(history.history['val_accuracy'])\nplt.xlabel('cross val acc')\nplt.ylabel('epochs')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#binaryhealthy27 are the best binary model weights","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"############################################################MAKING PREDICTIONS#################################################################\n\n\n###################BINARY MODEL###################################\n\nmodel_1 = efn.EfficientNetB0(weights='imagenet',include_top = False, input_shape = (256,256,3),pooling = 'avg')\nmodel_1 = Sequential([model_1])\nmodel_1.add(Dense(1024,activation = 'sigmoid'))\nmodel_1.add(Dense(128,activation = 'relu'))\nmodel_1.add(Dense(2,activation = 'softmax'))\nmodel_1.compile(loss='binary_crossentropy',optimizer = 'adam',metrics=['accuracy'])\n\nmodel_1.load_weights('../input/weights/binaryhealthy_27.h5')\n\nprint('0')\n#################MULTICLASS MODEL##################################\n\nX1 = efn.EfficientNetB0(weights='imagenet',include_top = False,input_shape=(256,256,3),pooling='avg')\nX0 = Dense(1024,activation='sigmoid')(X1.layers[-1].output)\nX02 = Dense(128,activation='relu')(X0)\nX2 = Dense(2,activation='softmax',name='x2_1')(X02)\nX3 = Dense(2,activation='softmax',name='x2_2')(X02)\nX4 = Dense(2,activation='softmax',name='x2_3')(X02)\n\nmodel_2 = Model(X1.inputs,[X2,X3,X4])\nmodel_2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nmodel_2.load_weights('../input/weights/multiclass_28_extralayers.h5')\n\nprint('2')\n####################################################################TEST DATASET#############################################\nTest_images_gc = []\nfor id,img in enumerate(Test_paths_gc):\n  image = cv2.imread(img)\n    #image = cv2.rotate(image, cv2.ROTATE_180)\n  Test_images_gc.append(image/255)\n  if id%100==0:\n     print(id)\nprint('3')\n\n\n\n################################################Looping Predictions############################################### NOT WORKING FOR SINGLE IMAGE\n#predictions = pd.DataFrame(np.zeros((1821,4)).astype(int),columns=['healthy','multiple_diseases','rust','scab'])\n\n#for id,image in enumerate(Test_images_gc):\n#    predict = model_1.predict(np.array(image))\n#    Predict = ohe.inverse_transform(predict)\n#    predictions['healthy'][id] = Predict\n#    if predictions['healthy'][id] == 1:\n#        continue\n#    else:\n#        [predict1,predict2,predict3] = model_2.predict(np.array(image))\n#        Predict1 = ohe.inverse_transform(predict1)\n#        Predict2 = ohe.inverse_transform(predict2)\n#        Predict3 = ohe.inverse_transform(predict3)\n\n#        predictions['multiple_diseases'][id] = Predict1\n#        predictions['rust'][id] = Predict2\n#        predictions['scab'][id] = Predict3\n#    if id%100 ==0:\n#        print(id)\n#predictions.to_csv('/kaggle/working/Submission23:39.csv',index=False)\n\n##################################################\n\npredict = model_1.predict(np.array(Test_images_gc))\nPredict = ohe.inverse_transform(predict)\nPredictions = pd.concat([test,pd.DataFrame(Predict)],axis=1)\n\n\n\n[predict1,predict2,predict3] = model_2.predict(np.array(Test_images_gc))\nPredict1 = ohe.inverse_transform(predict1)\nPredict2 = ohe.inverse_transform(predict2)\nPredict3 = ohe.inverse_transform(predict3)\nPredictions = pd.concat([Predictions,pd.DataFrame(Predict1),pd.DataFrame(Predict2),pd.DataFrame(Predict3)],axis=1)\nPredictions.rename(columns = {0:'image_id',1:'healthy',2:'multiple_diseases',3:'rust',4:'scab'}).to_csv('/kaggle/working/SubmissionNonLoop.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = pd.DataFrame(np.zeros((1821,4)).astype(int),columns=['healthy','multiple_diseases','rust','scab'])\npredictions['healthy'][1] = 2\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor id in range(Predictions.shape[0]):\n    if Predictions.iloc[id,1] == 1:\n        Predictions.iloc[id,2] = 0\n        Predictions.iloc[id,3] = 0\n        Predictions.iloc[id,4] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Predictions.rename(columns = {0:'image_id',1:'healthy',2:'multiple_diseases',3:'rust',4:'scab'}).to_csv('/kaggle/working/SubmissionNonLoop2.csv',index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#######################SEPARATE PREDICTIONS ARE FAILING#####################################\nTrain_images_gc = []\nfor id,img in enumerate(train_paths_gc):\n  image = cv2.resize(cv2.imread(img),(256,256),cv2.INTER_AREA)\n    #image = cv2.random_rotate(image, cv2.ROTATE_180)\n  Train_images_gc.append(image/255)\n  if id%100==0:\n     print(id)\nprint('0')\n\n\n\n###########################APPLY THEM IN TOGETHER FORMAT##################################\nX1 = efn.EfficientNetB2(weights='imagenet',include_top = False,input_shape=(256,256,3),pooling='avg')\nX0 = Dense(1024,activation='sigmoid')(X1.layers[-1].output)\nX02 = Dense(128,activation='relu')(X0)\nX2 = Dense(2,activation='softmax',name='x2_1')(X02)\nX3 = Dense(2,activation='softmax',name='x2_2')(X02)\nX4 = Dense(2,activation='softmax',name='x2_3')(X02)\nX5 = Dense(2,activation='softmax',name='x2_4')(X02)\n\nmodel = Model(X1.inputs,[X2,X3,X4,X5])\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\n\n\nprint('1')\n#model.fit(np.array(Train_images_gc),{'x2_1':train_labels_healthy_one_hot,'x2_2':train_labels_multiple_diseases_one_hot,'x2_3':train_labels_rust_one_hot,'x2_4':train_labels_scab_one_hot},\n#          epochs=20,batch_size=64,validation_split=0.1,shuffle=True)\n#model.save_weights('/kaggle/working/multiclass_20_extralayers.h5')\n\nprint('2')\nmodel.load_weights('/kaggle/working/multiclass_20_extralayers.h5')\n\nmodel.fit(np.array(Train_images_gc),{'x2_1':train_labels_healthy_one_hot,'x2_2':train_labels_multiple_diseases_one_hot,'x2_3':train_labels_rust_one_hot,'x2_4':train_labels_scab_one_hot},\n          epochs=5,batch_size=64,validation_split=0.1,shuffle=True)\nmodel.save_weights('/kaggle/working/multiclass_25_extralayers.h5')\n\nprint('3')\nadam = Adam(learning_rate=0.0003)\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\nmodel.load_weights('/kaggle/working/multiclass_25_extralayers.h5')\n\nmodel.fit(np.array(Train_images_gc),{'x2_1':train_labels_healthy_one_hot,'x2_2':train_labels_multiple_diseases_one_hot,'x2_3':train_labels_rust_one_hot,'x2_4':train_labels_scab_one_hot},\n          epochs=5,batch_size=64,validation_split=0.1,shuffle=True)\nmodel.save_weights('/kaggle/working/multiclass_30_extralayers.h5')\n\nprint('4')\nadam = Adam(learning_rate=0.0003)\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\n\nmodel.load_weights('/kaggle/working/multiclass_30_extralayers.h5')\n\nmodel.fit(np.array(Train_images_gc),{'x2_1':train_labels_healthy_one_hot,'x2_2':train_labels_multiple_diseases_one_hot,'x2_3':train_labels_rust_one_hot,'x2_4':train_labels_scab_one_hot},\n          epochs=3,batch_size=64,validation_split=0.1,shuffle=True)\nmodel.save_weights('/kaggle/working/multiclass_33_extralayers.h5')\n\nprint('5')\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\nmodel.load_weights('/kaggle/working/multiclass_33_extralayers.h5')\n\nmodel.fit(np.array(Train_images_gc),{'x2_1':train_labels_healthy_one_hot,'x2_2':train_labels_multiple_diseases_one_hot,'x2_3':train_labels_rust_one_hot,'x2_4':train_labels_scab_one_hot},\n          epochs=3,batch_size=64,validation_split=0.1,shuffle=True)\nmodel.save_weights('/kaggle/working/multiclass_36_extralayers.h5')\n\nprint('6')\n\nmodel.compile(loss='binary_crossentropy',optimizer=adam,metrics=['accuracy'])\nmodel.load_weights('/kaggle/working/multiclass_36_extralayers.h5')\n\nmodel.fit(np.array(Train_images_gc),{'x2_1':train_labels_healthy_one_hot,'x2_2':train_labels_multiple_diseases_one_hot,'x2_3':train_labels_rust_one_hot,'x2_4':train_labels_scab_one_hot},\n          epochs=3,batch_size=64,validation_split=0.1,shuffle=True)\nmodel.save_weights('/kaggle/working/multiclass_39_extralayers.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nmodel_name = 'effNetPlants.h5'\n\n#good callbacks\nbest_model = ModelCheckpoint(model_name, monitor='val_loss', verbose=1, save_best_only=True,save_weights_only=True,mode='min')\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.5,verbose=1,min_lr=0.000001,patience=6)\n\nBATCH_SIZE = 64\n\n\n\ndef get_model():\n    base_model = efn.EfficientNetB7(weights='imagenet',\n                          include_top=False,\n                          input_shape=(IMG_SIZE,IMG_SIZE, 3),\n                          pooling='avg')\n    x = base_model.output\n    predictions = Dense(nb_classes, activation=\"softmax\")(x)\n    return Model(inputs=base_model.input, outputs=predictions)\n\nwith strategy.scope():\n    model = get_model()\n\nopt = Adam(lr=0.001)\nmodel.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['categorical_accuracy'])\nprint('2')\n\nimport tensorflow as tf, tensorflow.keras.backend as K\n\n\nhistory = model.fit(train_dataset,\n                    steps_per_epoch = train.shape[0]//BATCH_SIZE,\n                    epochs=40,\n                    verbose=1,\n                    validation_data=val_dataset,\n                    callbacks=[reduce_lr,best_model]\n                    )\n\nmodel.save_weights('/kaggle/working/tpu40.h5')\nplt.title('model accuracy')\nplt.plot(history.history['val_accuracy'])\nplt.plot(history.history['accuracy'])\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['val_accuracy'])\nplt.xlabel('cross val acc sigmoid 40 epochs 450 img size')\nplt.ylabel('epochs')\nplt.show()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('/kaggle/working/MultiClassWeights.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n\n\n\n\n#model.load_weights('../input/qwerty/categorical.h5')    #######################BEST WEIGHTS\n\npredict1 = model.predict(test_dataset,verbose=1)\n#Predict1 = ohe.inverse_transform(predict1)\n#Predict2 = ohe.inverse_transform(predict2)\n#Predict3 = ohe.inverse_transform(predict3)\n#Predict4 = ohe.inverse_transform(predict4)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict1 = model.predict(test_dataset,steps=test.shape[0]//64,verbose=1)\nPredictions = pd.concat([test,pd.DataFrame(predict1)],axis=1)\n#for id in range(Predictions.shape[0]):\n#    if Predictions.iloc[id,1] == 1:\n#        Predictions.iloc[id,2] = 0\n#        Predictions.iloc[id,3] = 0\n#        Predictions.iloc[id,4] = 0\n#    else:\n#        continue\n\nPredictions.rename(columns = {0:'image_id',1:'healthy',2:'multiple_diseases',3:'rust',4:'scab'}).to_csv('/kaggle/working/SubmissionMultiClass.csv',index=False)\nprint('1')\n###########################Predictions on which i am working are downloaded as SubmissionMultiClass.csv###################################################3\nPredictions_readable = pd.DataFrame(np.zeros((1821,4)),columns=['healthy','multiple_diseases','rust','scab'])\nfor id in range(Predictions.shape[0]):\n    if Predictions.iloc[id,1] >= 0.125:\n        Predictions_readable['healthy'][id] = 1\n    else:\n        Predictions_readable['healthy'][id] = 0\n        \n        \n    if Predictions.iloc[id,2] >= 0.125:\n        Predictions_readable['multiple_diseases'][id] = 1\n    else:\n        Predictions_readable['multiple_diseases'][id] = 0\n        \n        \n    if Predictions.iloc[id,3] >= 0.125:\n        Predictions_readable['rust'][id] = 1\n    else:\n        Predictions_readable['rust'][id] = 0\n        \n        \n    if Predictions.iloc[id,4] >= 0.125:\n        Predictions_readable['scab'][id] = 1\n    else:\n        Predictions_readable['scab'][id] = 0\n    if id%100 == 0:\n        print(id)\nPredictions_readable = pd.concat([test,Predictions_readable],axis=1)\nPredictions_readable.to_csv('/kaggle/working/SubSubSub.csv',index=False)\nprint('2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('/kaggle/working/multiclass50epochs.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for id,val in enumerate(Predictions):\n    if Predictions.iloc[id,1] >= 0.5:\n        Predictions.iloc[id,1] = 1\n    else:\n        Predictions.iloc[id,1] = 0\n    \n    if Predictions.iloc[id,2] >= 0.5:\n        Predictions.iloc[id,2] = 1\n    else:\n        Predictions.iloc[id,2] = 0\n        \n    if Predictions.iloc[id,3] >= 0.5:\n        Predictions.iloc[id,3] = 1\n    else:\n        Predictions.iloc[id,3] = 0 \n        \n    if Predictions.iloc[id,4] >= 0.5:\n        Predictions.iloc[id,4] = 1\n    else:\n        Predictions.iloc[id,4] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Predictions = pd.concat([test,pd.DataFrame(predict1)],axis=1)\n\nPredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Predictions.rename(columns = {0:'image_id',1:'healthy',2:'multiple_diseases',3:'rust',4:'scab'}).to_csv('/kaggle/working/SubmissionMultiClass.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Predictions.iloc[2,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###########################Predictions on which i am working are downloaded as SubmissionMultiClass.csv###################################################3\nPredictions_readable = pd.DataFrame(np.zeros((1821,4)),columns=['healthy','multiple_diseases','rust','scab'])\nfor id in range(Predictions.shape[0]):\n    if Predictions.iloc[id,1] >= 0.125:\n        Predictions_readable['healthy'][id] = 1\n    else:\n        Predictions_readable['healthy'][id] = 0\n        \n        \n    if Predictions.iloc[id,2] >= 0.125:\n        Predictions_readable['multiple_diseases'][id] = 1\n    else:\n        Predictions_readable['multiple_diseases'][id] = 0\n        \n        \n    if Predictions.iloc[id,3] >= 0.125:\n        Predictions_readable['rust'][id] = 1\n    else:\n        Predictions_readable['rust'][id] = 0\n        \n        \n    if Predictions.iloc[id,4] >= 0.125:\n        Predictions_readable['scab'][id] = 1\n    else:\n        Predictions_readable['scab'][id] = 0\n    if id%100 == 0:\n        print(id)\nPredictions_readable = pd.concat([test,Predictions_readable],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Predictions_readable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Predictions_readable.to_csv('/kaggle/working/SubSubSub.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.imread(Train_paths_gc[1])\nimage","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path2 = '../input/kaggle-plant-pathology-1/images_withborder_train-20200524T112202Z-001/images_withborder_train'\npath3 = '../input/kaggle-plant-pathology-1/images_withborder_test-20200524T113820Z-001/images_withborder_test'\n\nfilenames = os.listdir(path2)\n\nint_files = []\nfor id in range(len(filenames)):\n  int_files.append(filenames[id].split('.')[0])\n\nfor id,img in enumerate(Train_paths_gc):\n  if img.split('.')[0].split('/')[-1] in int_files:\n    Train_paths_gc[id] = os.path.join(path2,'Train_'+str(id)+'.jpg')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(cv2.imread(Train_paths_gc[1]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}